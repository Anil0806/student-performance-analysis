{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d84095b0-2f5a-461d-be78-561e611c5176",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b15285c2-ed67-4e8d-a59d-df05107cae0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"StudentsPerformance.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cf5ab582-bba1-4976-83a2-24906f207891",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>race/ethnicity</th>\n",
       "      <th>parental level of education</th>\n",
       "      <th>lunch</th>\n",
       "      <th>test preparation course</th>\n",
       "      <th>math score</th>\n",
       "      <th>reading score</th>\n",
       "      <th>writing score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>female</td>\n",
       "      <td>group B</td>\n",
       "      <td>bachelor's degree</td>\n",
       "      <td>standard</td>\n",
       "      <td>none</td>\n",
       "      <td>72</td>\n",
       "      <td>72</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>female</td>\n",
       "      <td>group C</td>\n",
       "      <td>some college</td>\n",
       "      <td>standard</td>\n",
       "      <td>completed</td>\n",
       "      <td>69</td>\n",
       "      <td>90</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>female</td>\n",
       "      <td>group B</td>\n",
       "      <td>master's degree</td>\n",
       "      <td>standard</td>\n",
       "      <td>none</td>\n",
       "      <td>90</td>\n",
       "      <td>95</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>male</td>\n",
       "      <td>group A</td>\n",
       "      <td>associate's degree</td>\n",
       "      <td>free/reduced</td>\n",
       "      <td>none</td>\n",
       "      <td>47</td>\n",
       "      <td>57</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>male</td>\n",
       "      <td>group C</td>\n",
       "      <td>some college</td>\n",
       "      <td>standard</td>\n",
       "      <td>none</td>\n",
       "      <td>76</td>\n",
       "      <td>78</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>female</td>\n",
       "      <td>group B</td>\n",
       "      <td>associate's degree</td>\n",
       "      <td>standard</td>\n",
       "      <td>none</td>\n",
       "      <td>71</td>\n",
       "      <td>83</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>female</td>\n",
       "      <td>group B</td>\n",
       "      <td>some college</td>\n",
       "      <td>standard</td>\n",
       "      <td>completed</td>\n",
       "      <td>88</td>\n",
       "      <td>95</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>male</td>\n",
       "      <td>group B</td>\n",
       "      <td>some college</td>\n",
       "      <td>free/reduced</td>\n",
       "      <td>none</td>\n",
       "      <td>40</td>\n",
       "      <td>43</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>male</td>\n",
       "      <td>group D</td>\n",
       "      <td>high school</td>\n",
       "      <td>free/reduced</td>\n",
       "      <td>completed</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>female</td>\n",
       "      <td>group B</td>\n",
       "      <td>high school</td>\n",
       "      <td>free/reduced</td>\n",
       "      <td>none</td>\n",
       "      <td>38</td>\n",
       "      <td>60</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   gender race/ethnicity parental level of education         lunch  \\\n",
       "0  female        group B           bachelor's degree      standard   \n",
       "1  female        group C                some college      standard   \n",
       "2  female        group B             master's degree      standard   \n",
       "3    male        group A          associate's degree  free/reduced   \n",
       "4    male        group C                some college      standard   \n",
       "5  female        group B          associate's degree      standard   \n",
       "6  female        group B                some college      standard   \n",
       "7    male        group B                some college  free/reduced   \n",
       "8    male        group D                 high school  free/reduced   \n",
       "9  female        group B                 high school  free/reduced   \n",
       "\n",
       "  test preparation course  math score  reading score  writing score  \n",
       "0                    none          72             72             74  \n",
       "1               completed          69             90             88  \n",
       "2                    none          90             95             93  \n",
       "3                    none          47             57             44  \n",
       "4                    none          76             78             75  \n",
       "5                    none          71             83             78  \n",
       "6               completed          88             95             92  \n",
       "7                    none          40             43             39  \n",
       "8               completed          64             64             67  \n",
       "9                    none          38             60             50  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3aafc4e1-b3c4-47b7-bc0e-60e0608c7da9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 8 columns):\n",
      " #   Column                       Non-Null Count  Dtype \n",
      "---  ------                       --------------  ----- \n",
      " 0   gender                       1000 non-null   object\n",
      " 1   race/ethnicity               1000 non-null   object\n",
      " 2   parental level of education  1000 non-null   object\n",
      " 3   lunch                        1000 non-null   object\n",
      " 4   test preparation course      1000 non-null   object\n",
      " 5   math score                   1000 non-null   int64 \n",
      " 6   reading score                1000 non-null   int64 \n",
      " 7   writing score                1000 non-null   int64 \n",
      "dtypes: int64(3), object(5)\n",
      "memory usage: 62.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8b96bdbe-a9cb-45a4-aad6-b0db520c7050",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>race/ethnicity</th>\n",
       "      <th>parental level of education</th>\n",
       "      <th>lunch</th>\n",
       "      <th>test preparation course</th>\n",
       "      <th>math score</th>\n",
       "      <th>reading score</th>\n",
       "      <th>writing score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>593</th>\n",
       "      <td>female</td>\n",
       "      <td>group E</td>\n",
       "      <td>high school</td>\n",
       "      <td>standard</td>\n",
       "      <td>none</td>\n",
       "      <td>74</td>\n",
       "      <td>76</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>431</th>\n",
       "      <td>female</td>\n",
       "      <td>group C</td>\n",
       "      <td>high school</td>\n",
       "      <td>standard</td>\n",
       "      <td>none</td>\n",
       "      <td>61</td>\n",
       "      <td>72</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>908</th>\n",
       "      <td>female</td>\n",
       "      <td>group C</td>\n",
       "      <td>bachelor's degree</td>\n",
       "      <td>free/reduced</td>\n",
       "      <td>none</td>\n",
       "      <td>67</td>\n",
       "      <td>75</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>female</td>\n",
       "      <td>group D</td>\n",
       "      <td>associate's degree</td>\n",
       "      <td>standard</td>\n",
       "      <td>none</td>\n",
       "      <td>71</td>\n",
       "      <td>71</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>male</td>\n",
       "      <td>group A</td>\n",
       "      <td>master's degree</td>\n",
       "      <td>free/reduced</td>\n",
       "      <td>none</td>\n",
       "      <td>73</td>\n",
       "      <td>74</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>719</th>\n",
       "      <td>male</td>\n",
       "      <td>group E</td>\n",
       "      <td>associate's degree</td>\n",
       "      <td>free/reduced</td>\n",
       "      <td>completed</td>\n",
       "      <td>91</td>\n",
       "      <td>73</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>male</td>\n",
       "      <td>group C</td>\n",
       "      <td>high school</td>\n",
       "      <td>free/reduced</td>\n",
       "      <td>completed</td>\n",
       "      <td>53</td>\n",
       "      <td>51</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>737</th>\n",
       "      <td>female</td>\n",
       "      <td>group B</td>\n",
       "      <td>some college</td>\n",
       "      <td>free/reduced</td>\n",
       "      <td>completed</td>\n",
       "      <td>53</td>\n",
       "      <td>66</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>460</th>\n",
       "      <td>male</td>\n",
       "      <td>group C</td>\n",
       "      <td>bachelor's degree</td>\n",
       "      <td>free/reduced</td>\n",
       "      <td>none</td>\n",
       "      <td>53</td>\n",
       "      <td>58</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>537</th>\n",
       "      <td>female</td>\n",
       "      <td>group D</td>\n",
       "      <td>high school</td>\n",
       "      <td>standard</td>\n",
       "      <td>none</td>\n",
       "      <td>51</td>\n",
       "      <td>66</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     gender race/ethnicity parental level of education         lunch  \\\n",
       "593  female        group E                 high school      standard   \n",
       "431  female        group C                 high school      standard   \n",
       "908  female        group C           bachelor's degree  free/reduced   \n",
       "87   female        group D          associate's degree      standard   \n",
       "25     male        group A             master's degree  free/reduced   \n",
       "719    male        group E          associate's degree  free/reduced   \n",
       "166    male        group C                 high school  free/reduced   \n",
       "737  female        group B                some college  free/reduced   \n",
       "460    male        group C           bachelor's degree  free/reduced   \n",
       "537  female        group D                 high school      standard   \n",
       "\n",
       "    test preparation course  math score  reading score  writing score  \n",
       "593                    none          74             76             73  \n",
       "431                    none          61             72             70  \n",
       "908                    none          67             75             72  \n",
       "87                     none          71             71             74  \n",
       "25                     none          73             74             72  \n",
       "719               completed          91             73             80  \n",
       "166               completed          53             51             51  \n",
       "737               completed          53             66             73  \n",
       "460                    none          53             58             55  \n",
       "537                    none          51             66             62  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "25a2c94b-332f-4a68-ac97-79a53ada5fc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>math score</th>\n",
       "      <th>reading score</th>\n",
       "      <th>writing score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1000.00000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>66.08900</td>\n",
       "      <td>69.169000</td>\n",
       "      <td>68.054000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>15.16308</td>\n",
       "      <td>14.600192</td>\n",
       "      <td>15.195657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>57.00000</td>\n",
       "      <td>59.000000</td>\n",
       "      <td>57.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>66.00000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>69.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>77.00000</td>\n",
       "      <td>79.000000</td>\n",
       "      <td>79.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>100.00000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       math score  reading score  writing score\n",
       "count  1000.00000    1000.000000    1000.000000\n",
       "mean     66.08900      69.169000      68.054000\n",
       "std      15.16308      14.600192      15.195657\n",
       "min       0.00000      17.000000      10.000000\n",
       "25%      57.00000      59.000000      57.750000\n",
       "50%      66.00000      70.000000      69.000000\n",
       "75%      77.00000      79.000000      79.000000\n",
       "max     100.00000     100.000000     100.000000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "358b5d42-bcbb-47f9-a903-a453d21e02df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gender                         0\n",
       "race/ethnicity                 0\n",
       "parental level of education    0\n",
       "lunch                          0\n",
       "test preparation course        0\n",
       "math score                     0\n",
       "reading score                  0\n",
       "writing score                  0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "acbe28db-4451-4981-ad58-c6d2e279c97e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (1000, 8)\n",
      "Any missing values?\n",
      " gender                         0\n",
      "race/ethnicity                 0\n",
      "parental level of education    0\n",
      "lunch                          0\n",
      "test preparation course        0\n",
      "math score                     0\n",
      "reading score                  0\n",
      "writing score                  0\n",
      "dtype: int64\n",
      "Training samples: 800, Test samples: 200\n",
      "\n",
      "Test RMSE: 6.0006\n",
      "Test R²: 0.8520\n",
      "\n",
      "Top 10 Most Important Features:\n",
      "                                     Feature  Importance\n",
      "12                             reading score    0.558329\n",
      "13                             writing score    0.239531\n",
      "0                                gender_male    0.120352\n",
      "10                            lunch_standard    0.015644\n",
      "11              test preparation course_none    0.011459\n",
      "4                     race/ethnicity_group E    0.010635\n",
      "8   parental level of education_some college    0.008013\n",
      "2                     race/ethnicity_group C    0.006904\n",
      "6    parental level of education_high school    0.006351\n",
      "3                     race/ethnicity_group D    0.006005\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# OPTION 1: RECOMMENDED - Save the full CSV to a file and load it\n",
    "# Save all the content you provided (including the header line) as 'StudentsPerformance.csv'\n",
    "df = pd.read_csv('StudentsPerformance.csv')   # Place file in your working directory\n",
    "\n",
    "# OPTION 2: If you must use string (ONLY if you paste the FULL 1001 lines)\n",
    "# from io import StringIO\n",
    "# csv_data = \"\"\"gender,race/ethnicity,parental level of education,lunch,test preparation course,math score,reading score,writing score\n",
    "# female,group B,bachelor's degree,standard,none,72,72,74\n",
    "# ... paste ALL 1000 rows here exactly ...\n",
    "# female,group D,some college,free/reduced,none,77,86,86\"\"\"\n",
    "# df = pd.read_csv(StringIO(csv_data))\n",
    "\n",
    "# Quick sanity check\n",
    "print(\"Dataset shape:\", df.shape)  # Should be (1000, 8)\n",
    "print(\"Any missing values?\\n\", df.isnull().sum())\n",
    "\n",
    "# Target and features\n",
    "X = df.drop('math score', axis=1)\n",
    "y = df['math score']\n",
    "\n",
    "categorical_features = ['gender', 'race/ethnicity', 'parental level of education',\n",
    "                        'lunch', 'test preparation course']\n",
    "numerical_features = ['reading score', 'writing score']\n",
    "\n",
    "# Preprocessor - with handle_unknown='ignore' to fix the unknown categories warning\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', OneHotEncoder(drop='first', handle_unknown='ignore'), categorical_features),\n",
    "        ('num', 'passthrough', numerical_features)\n",
    "    ])\n",
    "\n",
    "# Model\n",
    "model = RandomForestRegressor(n_estimators=200, random_state=42)\n",
    "\n",
    "# Pipeline\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model', model)\n",
    "])\n",
    "\n",
    "# Split - 20% test gives 200 samples, plenty for reliable metrics\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Training samples: {len(X_train)}, Test samples: {len(X_test)}\")\n",
    "\n",
    "# Train and evaluate\n",
    "pipeline.fit(X_train, y_train)\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"\\nTest RMSE: {rmse:.4f}\")\n",
    "print(f\"Test R²: {r2:.4f}\")\n",
    "\n",
    "# Feature importances\n",
    "ohe_names = pipeline.named_steps['preprocessor'].named_transformers_['cat'].get_feature_names_out(categorical_features)\n",
    "feature_names = list(ohe_names) + numerical_features\n",
    "\n",
    "importances = pipeline.named_steps['model'].feature_importances_\n",
    "feature_importance_df = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Importance': importances\n",
    "}).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "print(\"\\nTop 10 Most Important Features:\")\n",
    "print(feature_importance_df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7621ead6-6a26-4bcf-b4ce-1c58510fd1b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (1000, 8)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 8 columns):\n",
      " #   Column                       Non-Null Count  Dtype \n",
      "---  ------                       --------------  ----- \n",
      " 0   gender                       1000 non-null   object\n",
      " 1   race/ethnicity               1000 non-null   object\n",
      " 2   parental level of education  1000 non-null   object\n",
      " 3   lunch                        1000 non-null   object\n",
      " 4   test preparation course      1000 non-null   object\n",
      " 5   math score                   1000 non-null   int64 \n",
      " 6   reading score                1000 non-null   int64 \n",
      " 7   writing score                1000 non-null   int64 \n",
      "dtypes: int64(3), object(5)\n",
      "memory usage: 62.6+ KB\n",
      "None\n",
      "Training samples: 800, Test samples: 200\n",
      "\n",
      "=== Gradient Boosting Regressor Results ===\n",
      "Test RMSE: 5.6371\n",
      "Test R²:   0.8694\n",
      "\n",
      "Top 15 Most Important Features:\n",
      "                                          Feature  Importance\n",
      "12                                  reading score    0.535245\n",
      "13                                  writing score    0.253569\n",
      "0                                     gender_male    0.143054\n",
      "10                                 lunch_standard    0.023106\n",
      "4                          race/ethnicity_group E    0.014436\n",
      "11                   test preparation course_none    0.009160\n",
      "6         parental level of education_high school    0.003773\n",
      "8        parental level of education_some college    0.003428\n",
      "2                          race/ethnicity_group C    0.003089\n",
      "1                          race/ethnicity_group B    0.002929\n",
      "9    parental level of education_some high school    0.002782\n",
      "3                          race/ethnicity_group D    0.001996\n",
      "5   parental level of education_bachelor's degree    0.001884\n",
      "7     parental level of education_master's degree    0.001549\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Load your dataset\n",
    "# If you saved it as a file:\n",
    "df = pd.read_csv('StudentsPerformance.csv')\n",
    "\n",
    "# If you're working in a notebook and the data is already loaded as df, skip the line above\n",
    "\n",
    "# Quick check\n",
    "print(\"Dataset shape:\", df.shape)\n",
    "print(df.info())\n",
    "\n",
    "# Features and target\n",
    "X = df.drop('math score', axis=1)\n",
    "y = df['math score']\n",
    "\n",
    "# Categorical and numerical columns\n",
    "categorical_features = ['gender', 'race/ethnicity', 'parental level of education',\n",
    "                        'lunch', 'test preparation course']\n",
    "numerical_features = ['reading score', 'writing score']\n",
    "\n",
    "# Preprocessor: One-hot encode categorical variables\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', OneHotEncoder(drop='first', handle_unknown='ignore'), categorical_features),\n",
    "        ('num', 'passthrough', numerical_features)  # reading & writing scores pass through\n",
    "    ])\n",
    "\n",
    "# Gradient Boosting Regressor\n",
    "# You can tune these hyperparameters later\n",
    "gb_model = GradientBoostingRegressor(\n",
    "    n_estimators=300,       # number of boosting stages\n",
    "    learning_rate=0.05,     # smaller learning rate often better\n",
    "    max_depth=4,            # controls tree complexity\n",
    "    random_state=42,\n",
    "    subsample=0.9,          # introduces stochasticity, reduces overfitting\n",
    "    loss='squared_error'\n",
    ")\n",
    "\n",
    "# Pipeline\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model', gb_model)\n",
    "])\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Training samples: {X_train.shape[0]}, Test samples: {X_test.shape[0]}\")\n",
    "\n",
    "# Train the model\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "# Evaluation\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"\\n=== Gradient Boosting Regressor Results ===\")\n",
    "print(f\"Test RMSE: {rmse:.4f}\")\n",
    "print(f\"Test R²:   {r2:.4f}\")\n",
    "\n",
    "# Feature Importances\n",
    "# Get feature names after one-hot encoding\n",
    "ohe = pipeline.named_steps['preprocessor'].named_transformers_['cat']\n",
    "feature_names = ohe.get_feature_names_out(categorical_features).tolist() + numerical_features\n",
    "\n",
    "importances = pipeline.named_steps['model'].feature_importances_\n",
    "feature_importance_df = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Importance': importances\n",
    "}).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "print(\"\\nTop 15 Most Important Features:\")\n",
    "print(feature_importance_df.head(15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "edac39b9-8034-471f-844c-482628bec665",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (1000, 8)\n",
      "Missing values:\n",
      " gender                         0\n",
      "race/ethnicity                 0\n",
      "parental level of education    0\n",
      "lunch                          0\n",
      "test preparation course        0\n",
      "math score                     0\n",
      "reading score                  0\n",
      "writing score                  0\n",
      "dtype: int64\n",
      "Training samples: 800, Test samples: 200\n",
      "\n",
      "=== XGBoost Regressor Results ===\n",
      "Test RMSE: 5.9107\n",
      "Test R²:   0.8564\n",
      "\n",
      "Top 15 Most Important Features:\n",
      "                                          Feature  Importance\n",
      "0                                     gender_male    0.270520\n",
      "1                                   reading score    0.230517\n",
      "2                                   writing score    0.163896\n",
      "3                                  lunch_standard    0.066297\n",
      "4                          race/ethnicity_group E    0.062504\n",
      "5                    test preparation course_none    0.034158\n",
      "6                          race/ethnicity_group C    0.025952\n",
      "7        parental level of education_some college    0.025106\n",
      "8         parental level of education_high school    0.022647\n",
      "9     parental level of education_master's degree    0.021562\n",
      "10  parental level of education_bachelor's degree    0.020430\n",
      "11                         race/ethnicity_group D    0.019472\n",
      "12   parental level of education_some high school    0.018479\n",
      "13                         race/ethnicity_group B    0.018461\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Install XGBoost if needed (run once)\n",
    "# !pip install xgboost\n",
    "\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('StudentsPerformance.csv')  # Ensure the file is in your working directory\n",
    "\n",
    "# Quick sanity check\n",
    "print(\"Dataset shape:\", df.shape)\n",
    "print(\"Missing values:\\n\", df.isnull().sum())\n",
    "\n",
    "# Features and target\n",
    "X = df.drop('math score', axis=1)\n",
    "y = df['math score']\n",
    "\n",
    "# Categorical and numerical features\n",
    "categorical_features = ['gender', 'race/ethnicity', 'parental level of education',\n",
    "                        'lunch', 'test preparation course']\n",
    "numerical_features = ['reading score', 'writing score']\n",
    "\n",
    "# Preprocessor\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', OneHotEncoder(drop='first', handle_unknown='ignore'), categorical_features),\n",
    "        ('num', 'passthrough', numerical_features)\n",
    "    ])\n",
    "\n",
    "# XGBoost model\n",
    "xgb_model = XGBRegressor(\n",
    "    n_estimators=400,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=5,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    random_state=42,\n",
    "    objective='reg:squarederror',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Pipeline\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model', xgb_model)\n",
    "])\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Training samples: {X_train.shape[0]}, Test samples: {X_test.shape[0]}\")\n",
    "\n",
    "# Train\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"\\n=== XGBoost Regressor Results ===\")\n",
    "print(f\"Test RMSE: {rmse:.4f}\")\n",
    "print(f\"Test R²:   {r2:.4f}\")\n",
    "\n",
    "# Feature Importances (FIXED LINE HERE)\n",
    "ohe = pipeline.named_steps['preprocessor'].named_transformers_['cat']\n",
    "feature_names = ohe.get_feature_names_out(categorical_features).tolist() + numerical_features\n",
    "\n",
    "importances = pipeline.named_steps['model'].feature_importances_\n",
    "\n",
    "feature_importance_df = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Importance': importances\n",
    "}).sort_values(by='Importance', ascending=False).reset_index(drop=True)  # <-- Fixed: ascending=False\n",
    "\n",
    "print(\"\\nTop 15 Most Important Features:\")\n",
    "print(feature_importance_df.head(15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "032df1da-fb91-4cfb-ab60-1cb3237ef2d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (1000, 8)\n",
      "Missing values:\n",
      " gender                         0\n",
      "race/ethnicity                 0\n",
      "parental level of education    0\n",
      "lunch                          0\n",
      "test preparation course        0\n",
      "math score                     0\n",
      "reading score                  0\n",
      "writing score                  0\n",
      "dtype: int64\n",
      "Training samples: 800, Test samples: 200\n",
      "\n",
      "=== Random Forest Regressor Results ===\n",
      "Test RMSE: 6.0266\n",
      "Test R²:   0.8507\n",
      "\n",
      "Top 15 Most Important Features:\n",
      "                                          Feature  Importance\n",
      "0                                   reading score    0.558510\n",
      "1                                   writing score    0.238289\n",
      "2                                     gender_male    0.121160\n",
      "3                                  lunch_standard    0.015789\n",
      "4                    test preparation course_none    0.011520\n",
      "5                          race/ethnicity_group E    0.010542\n",
      "6        parental level of education_some college    0.007887\n",
      "7                          race/ethnicity_group C    0.006962\n",
      "8         parental level of education_high school    0.006418\n",
      "9                          race/ethnicity_group D    0.005946\n",
      "10                         race/ethnicity_group B    0.005253\n",
      "11  parental level of education_bachelor's degree    0.004758\n",
      "12   parental level of education_some high school    0.004744\n",
      "13    parental level of education_master's degree    0.002222\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('StudentsPerformance.csv')  # Make sure the file is in your working directory\n",
    "\n",
    "# Quick check\n",
    "print(\"Dataset shape:\", df.shape)\n",
    "print(\"Missing values:\\n\", df.isnull().sum())\n",
    "\n",
    "# Features and target\n",
    "X = df.drop('math score', axis=1)\n",
    "y = df['math score']\n",
    "\n",
    "# Categorical and numerical features\n",
    "categorical_features = ['gender', 'race/ethnicity', 'parental level of education',\n",
    "                        'lunch', 'test preparation course']\n",
    "numerical_features = ['reading score', 'writing score']\n",
    "\n",
    "# Preprocessor: One-hot encode categorical variables\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', OneHotEncoder(drop='first', handle_unknown='ignore'), categorical_features),\n",
    "        ('num', 'passthrough', numerical_features)\n",
    "    ])\n",
    "\n",
    "# Random Forest Regressor\n",
    "rf_model = RandomForestRegressor(\n",
    "    n_estimators=300,        # Number of trees (more = better, but slower)\n",
    "    max_depth=None,          # Let trees grow fully\n",
    "    min_samples_split=2,\n",
    "    min_samples_leaf=1,\n",
    "    random_state=42,\n",
    "    n_jobs=-1                # Use all CPU cores\n",
    ")\n",
    "\n",
    "# Pipeline\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model', rf_model)\n",
    "])\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Training samples: {X_train.shape[0]}, Test samples: {X_test.shape[0]}\")\n",
    "\n",
    "# Train the model\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "# Evaluation\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"\\n=== Random Forest Regressor Results ===\")\n",
    "print(f\"Test RMSE: {rmse:.4f}\")\n",
    "print(f\"Test R²:   {r2:.4f}\")\n",
    "\n",
    "# Feature Importances\n",
    "ohe = pipeline.named_steps['preprocessor'].named_transformers_['cat']\n",
    "feature_names = ohe.get_feature_names_out(categorical_features).tolist() + numerical_features\n",
    "\n",
    "importances = pipeline.named_steps['model'].feature_importances_\n",
    "\n",
    "feature_importance_df = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Importance': importances\n",
    "}).sort_values(by='Importance', ascending=False).reset_index(drop=True)\n",
    "\n",
    "print(\"\\nTop 15 Most Important Features:\")\n",
    "print(feature_importance_df.head(15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9264b467-dba3-4b8e-98ae-73db5ad1400a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "MODEL PERFORMANCE COMPARISON (Predicting Math Score)\n",
      "============================================================\n",
      "                     RMSE      R²  RMSE Diff (vs Linear)  R² Diff (vs Linear)\n",
      "Linear Regression  5.3940  0.8804                 0.0000               0.0000\n",
      "Random Forest      6.0266  0.8507                 0.6326              -0.0297\n",
      "Gradient Boosting  5.6626  0.8682                 0.2686              -0.0122\n",
      "XGBoost            5.9107  0.8564                 0.5167              -0.0240\n",
      "============================================================\n",
      "Best R²:  Linear Regression (0.8804)\n",
      "Best RMSE: Linear Regression (5.394)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv('StudentsPerformance.csv')\n",
    "\n",
    "# Features and target\n",
    "X = df.drop('math score', axis=1)\n",
    "y = df['math score']\n",
    "\n",
    "# Categorical and numerical features\n",
    "categorical_features = ['gender', 'race/ethnicity', 'parental level of education',\n",
    "                        'lunch', 'test preparation course']\n",
    "numerical_features = ['reading score', 'writing score']\n",
    "\n",
    "# Preprocessor (same for all models)\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', OneHotEncoder(drop='first', handle_unknown='ignore'), categorical_features),\n",
    "        ('num', 'passthrough', numerical_features)\n",
    "    ])\n",
    "\n",
    "# Train-test split (same for all models)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Dictionary to store results\n",
    "results = {}\n",
    "\n",
    "# 1. Linear Regression (Baseline)\n",
    "lr_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model', LinearRegression())\n",
    "])\n",
    "lr_pipeline.fit(X_train, y_train)\n",
    "y_pred_lr = lr_pipeline.predict(X_test)\n",
    "results['Linear Regression'] = {\n",
    "    'RMSE': np.sqrt(mean_squared_error(y_test, y_pred_lr)),\n",
    "    'R²': r2_score(y_test, y_pred_lr)\n",
    "}\n",
    "\n",
    "# 2. Random Forest\n",
    "rf_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model', RandomForestRegressor(n_estimators=300, random_state=42, n_jobs=-1))\n",
    "])\n",
    "rf_pipeline.fit(X_train, y_train)\n",
    "y_pred_rf = rf_pipeline.predict(X_test)\n",
    "results['Random Forest'] = {\n",
    "    'RMSE': np.sqrt(mean_squared_error(y_test, y_pred_rf)),\n",
    "    'R²': r2_score(y_test, y_pred_rf)\n",
    "}\n",
    "\n",
    "# 3. Gradient Boosting\n",
    "gb_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model', GradientBoostingRegressor(n_estimators=300, learning_rate=0.05, \n",
    "                                        max_depth=4, random_state=42))\n",
    "])\n",
    "gb_pipeline.fit(X_train, y_train)\n",
    "y_pred_gb = gb_pipeline.predict(X_test)\n",
    "results['Gradient Boosting'] = {\n",
    "    'RMSE': np.sqrt(mean_squared_error(y_test, y_pred_gb)),\n",
    "    'R²': r2_score(y_test, y_pred_gb)\n",
    "}\n",
    "\n",
    "# 4. XGBoost\n",
    "xgb_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model', XGBRegressor(n_estimators=400, learning_rate=0.05, max_depth=5,\n",
    "                           subsample=0.8, colsample_bytree=0.8, random_state=42, n_jobs=-1))\n",
    "])\n",
    "xgb_pipeline.fit(X_train, y_train)\n",
    "y_pred_xgb = xgb_pipeline.predict(X_test)\n",
    "results['XGBoost'] = {\n",
    "    'RMSE': np.sqrt(mean_squared_error(y_test, y_pred_xgb)),\n",
    "    'R²': r2_score(y_test, y_pred_xgb)\n",
    "}\n",
    "\n",
    "# Create comparison DataFrame\n",
    "comparison_df = pd.DataFrame(results).T\n",
    "comparison_df = comparison_df.round(4)\n",
    "\n",
    "# Add difference columns (compared to Linear Regression)\n",
    "comparison_df['RMSE Diff (vs Linear)'] = (comparison_df['RMSE'] - comparison_df.loc['Linear Regression', 'RMSE']).round(4)\n",
    "comparison_df['R² Diff (vs Linear)'] = (comparison_df['R²'] - comparison_df.loc['Linear Regression', 'R²']).round(4)\n",
    "\n",
    "# Reorder columns\n",
    "comparison_df = comparison_df[['RMSE', 'R²', 'RMSE Diff (vs Linear)', 'R² Diff (vs Linear)']]\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"MODEL PERFORMANCE COMPARISON (Predicting Math Score)\")\n",
    "print(\"=\"*60)\n",
    "print(comparison_df)\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Highlight the best model\n",
    "best_r2 = comparison_df['R²'].idxmax()\n",
    "best_rmse = comparison_df['RMSE'].idxmin()\n",
    "print(f\"Best R²:  {best_r2} ({comparison_df.loc[best_r2, 'R²']})\")\n",
    "print(f\"Best RMSE: {best_rmse} ({comparison_df.loc[best_rmse, 'RMSE']})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a82af61-6bfe-41f2-987b-00b16dc392ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
